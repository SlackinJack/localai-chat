##################################################
############ BEGIN MAIN CONFIGURATION ############
##################################################


# address of the server
ADDRESS=http://localhost:8080/v1


# set default chat model
# leave empty for auto
# this is the 'front-end' model
CHAT_MODEL=jordan-7b


# set default prompt model
# leave empty for auto
# this is the 'back-end' model
COMPLETION_MODEL=jordan-7b


# enable considering conversation history (it will still write to file!)
# should disable if you are doing lots of unrelated prompts (eg. code generation)
# if you disable, i would suggest using 'burner conversation files'
# toggle at runtime with 'historyon' and 'historyoff'
CHAT_HISTORY_CONSIDERATION=False


# enable searching online
# useful if you want to strictly generate text (eg. code generation)
# you can toggle this at runtime with 'online' and 'offline'
ENABLE_INTERNET=False


# enable loopback on search
# it can be useful for complex prompts that require
# multiple searches for differing topics (eg. compare this vs that, pros and cons, etc)
# this can astronomically increase prompt times, especially on low-end hardware
# this will also add to future prompt times on the same conversation
# disable to prompt immediately after searching once
SEARCH_LOOPBACK=True


# max times to loopback
# set to a realistic number
# but not too low that we cant a good dataset
MAX_SEARCH_LOOPBACK_ITERATIONS=5


# set debug level
# 4 - all
# 3 - debug
# 2 - info
# 1 - error
# 0 - disable
DEBUG_LEVEL=4


# models to ignore (stablediffusion models, folders, etc.)
IGNORED_MODELS=stablediffusion,assets,configs,lunademo,example,test


# max number of sentences to consider
# when using online sources
# low values may affect data quality
# high values will increase processing time
# remember to (in/de)crease context size
MAX_SENTENCES=5


# max number of sources to consider
# when using online sources
# low values may affect data diversity
# high values will increase processing time
# remember to (in/de)crease context size 
MAX_SOURCES=2


# api key (cannot be empty)
KEY=sx-xxx


# automatically open files on completion
# eg. generated images, audio files, etc.
AUTO_OPEN_FILES=True


# UwU-ify your assistant.................
# yeah, no comment.
# outputs may literally be illegible
# very beta, probably broken to some extent
UWU_IFY=False


#################################################
###### BEGIN STABLEDIFFUSION CONFIGURATION ######
#################################################


# set default sd model
STABLE_DIFFUSION_MODEL=stablediffusion


# set image size
IMAGE_SIZE=256x256


